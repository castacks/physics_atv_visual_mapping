models_dir: /home/tartandriver/tartandriver_ws/models #necessary to include this for non-ROS offline proc

images:
    image_left_color:
        image_topic: /multisense/left/image_rect_color
        camera_info_topic: /multisense/left/camera_info
        image_compressed: False
        folder: image

        #camera intrinsics
        intrinsics:
            K: [455.7750, 0., 497.1180, 0., 456.3191, 251.8580, 0., 0., 1.]
            P: [455.7750, 0., 497.1180, 0., 456.3191, 251.8580, 0., 0., 1.]

        #transform from the vehicle link to the camera link
        extrinsics:
            p: [0.17265, -0.15227, 0.05708]
            q: [0.55940, -0.54718, 0.44603, 0.43442]


pointcloud:
   topic: /superodometry/velodyne_cloud_registered
   folder: pointcloud_in_odom

odometry:
    topic: /superodometry/integrated_to_init
    folder: odometry

gridmap:
    topic: local_gridmap
    folder: local_gridmap

#the base link of the vehicle (e.g. base_link, vehicle, etc.)
vehicle_frame: vehicle 

## define image processing pipeline (e.g. how to compute image-space features from raw)
image_processing: !include /home/tartandriver/tartandriver_ws/src/perception/physics_atv_visual_mapping/config/image_processing/jafar_vlad.yaml

## define localmapping representation (e.g. voxel/BEV, mapping extent, etc.)
localmapping: !include /home/tartandriver/tartandriver_ws/src/perception/physics_atv_visual_mapping/config/localmapping/voxel.yaml

## optionally, define how to compute a terrain representation from mapping representation
terrain_estimation: !include /home/tartandriver/tartandriver_ws/src/perception/physics_atv_visual_mapping/config/terrain_estimation/voxel_to_bev.yaml

device: cuda
viz: True

